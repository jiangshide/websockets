package cmd

/**
	1.弹幕技术复杂度
	1.1.个直播间：
	1.1.1.在线人数:100万
	1.1.2.发送弹幕:1000条/秒
	1.1.3.推送频率:100万*1000条/秒=10亿条/秒
	1.2.N个直播间:
	1.2.1.推送频率:N*10亿条/秒
	2.拉模式与推模式的区别
	2.1.拉模式
	2.1.1.数据更新频率低,则大多数请求是无效的
	2.1.2.在线用户数据量多,则服务端的查询负载很高
	2.1.3.定时轮询拉取,无法满足时效性要求
	2.2.推模式
	2.2.1.仅在数据更新时才需要推送
	2.2.2.需要维护大量的长连接
	2.2.3.数据更新后可以立即推送
	2.3.基于WebSocket推送
	2.3.1.浏览器支持的socket编程,轻松维持服务端的长连接
	2.3.2.基于TCP可靠传输之上的协议,无需开发者关心通讯细节
	2.3.3.提供了高度抽象的编程接口,业务开发成本较低
	3.掌握WebSocket协议
	3.1.通讯流程:client~server
	3.1.1.client->upgrade->server
	3.1.2.server->switching->client
	3.1.3.client->message->service
	3.1.4.server->message->client
	3.2.传输原理
	3.2.1.协议升级后,继续复用HTTP的底层SOCKET完成后续通讯
	3.2.2.message底层被切分成多个frame帧传输
	3.2.3.编程只需操作message,无需关心frame
	3.2.4.框架底层完成TCP网络I/O，WebSocket协议解析,开发者无需关系
	3.3.抓包观察
	3.3.1.使用chrome开发者工具,观察WebSocket通讯流程
	4.服务端的技术选型与考虑
	4.1.NodeJS
	4.1.1.单线程模型,推送性能有线
	4.2.C/C++
	4.2.1.TCP通讯,WebSocket协议实现成本高
	4.3.Go
	4.3.1.多线程,基于协程模型并发
	4.3.2.成熟的WebSocket标准库,无需造轮子
	5.GO实现WebSocket服务端
	5.1.实现Http服务端:github.com/gorilla/websocket
	5.1.1.WebSocket是http协议Upgrade而来的
	5.1.2.使用http标准库快速实现空接口:/ws
	5.2.完成WebSocket握手
	5.2.1.使用websocket.Upgrader完成协议握手,得到WebSocket长连接
	5.2.2.操作websocket api,读取客户端消息,然后原样发送回去
	5.3.封装WebSocket细节
	5.3.1.隐藏细节,封装API
	5.3.1.1.封装Connection结构,隐藏WebSocket底层连接
	5.3.1.2.封装Connection的API,提供Send/Read/Close等线程安全接口
	5.4.API原理
	5.4.1.SendMessage将消息投递到out channel
	5.4.2.ReadMessage从in channel读取消息
	5.4.3.启动读协程,循环读取WebSocket,将消息投递到in Channel
	5.4.4.启动写协程,循环读取out channel,将消息写给WebSocket
	6.技术难点
	6.1.个性能瓶颈
	6.1.1.内核瓶颈
	6.1.2.锁瓶颈
	6.1.3.CPU瓶颈
	6.2.内核瓶颈
	6.2.1.推送量:100万在线*10条/秒=1000万条/秒
	6.2.2.内核瓶颈：linux内核发送TCP的极限包频~100万/秒
	6.3.锁瓶颈
	6.3.1.需要维护在线用户集合(100万在线),通常是一个字典结构
	6.3.2.推送消息既遍历整个集合,顺序发送消息,耗时极长
	6.3.3.推送期间，客户端仍旧正常上/下线,所有集合需要上锁
	6.4.CPU瓶颈
	6.4.1.浏览器与服务器通常采取json格式通讯
	6.4.2.json编码非常耗费CPU资源
	6.4.3.向100万在线推送1次，则需要100万次json encode
	6.5.内核瓶颈~优化原理
	6.5.1.减少网络小包发送
	6.6.内核瓶颈~优化方案
	6.6.1.将同一秒内的N条消息,合并成1条消息
	6.6.2.合并后，每秒推送次数只等于在线连接数
	6.7.锁瓶颈~优化原理
	6.7.1.大拆小
	6.8.锁瓶颈~优化方案
	6.8.1.连接打散到多个集合中,每个集合有自己的锁
	6.8.2.多线程并发推送多个集合，避免锁竞争
	6.8.3.读写锁取代互斥锁，多个推送任务可以并发遍历相同集合
	6.9.CPU瓶颈~优化原理
	6.9.1.减少重复计算
	6.10.CPU瓶颈~优化方案
	6.10.1.json编码前置,1次消息编码+100万次推送
	6.10.2.消息合并前置,N条消息合并后只编码1次
	6.11.单价瓶颈
	6.11.1.维护海量长连接会花费不少内存
	6.11.2.消息推送瞬时消耗大量CPU资源
	6.11.3.消息推送瞬时带宽高达400~600MB(4~6Gbits)是主要瓶颈
	7.分布式架构
	7.1.网关集群
	7.2.逻辑集群
	7.2.1.基于HTTP/2协议向gateway集群分发消息
	7.2.1.1.HTTP/2支持连接复用,用作RPC性能更佳
	7.2.2.基于HTTP/1协议对外提供推送API
	7.2.2.1.HTTP/1更加普及,对业务方更佳友好
	7.3.整体架构
*/

